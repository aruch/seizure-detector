{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    import urllib2 as urllib\n",
    "except ImportError:\n",
    "    import urllib.request as urllib\n",
    "\n",
    "from nets import inception\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "image_size = inception.inception_v4.default_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy\n",
    "import moviepy.editor\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from box_client import get_box_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_box_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_video_folder = client.folder('61116096312')\n",
    "rat_video_feature_folder = client.folder('67339798174')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse practice seizures at 23 min in 71-2 and 70-3.MPG\n"
     ]
    }
   ],
   "source": [
    "box_video_ids = {}\n",
    "VID_PAT = re.compile(\"(\\w+).(MPG|MP4)$\")\n",
    "for day_folder in rat_video_folder.get_items():\n",
    "    try:\n",
    "        d = datetime.datetime.strptime(day_folder.name, \"%b %d %Y\")\n",
    "        d_str = d.strftime(\"%Y-%m-%d\")\n",
    "        box_video_ids[d_str] = {}\n",
    "    except Exception as e:\n",
    "        print(\"Unable to parse \" + day_folder.name)\n",
    "        continue\n",
    "    for cage_folder in day_folder.get_items():\n",
    "        box_video_ids[d_str][cage_folder.name] = {}\n",
    "        for video in cage_folder.get_items():\n",
    "            m = VID_PAT.match(video.name)\n",
    "            if m:\n",
    "                box_video_ids[d_str][cage_folder.name][m.groups()[0]] = video.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_feature_folder_ids = {}\n",
    "existing_days = {}\n",
    "for day_folder in rat_video_feature_folder.get_items():\n",
    "    existing_days[day_folder.name] = day_folder.id\n",
    "for day in box_video_ids:\n",
    "    box_feature_folder_ids[day] = {}\n",
    "    if day in existing_days:\n",
    "        day_folder = client.folder(existing_days[day]).get()\n",
    "    else:\n",
    "        day_folder = rat_video_feature_folder.create_subfolder(day)\n",
    "        \n",
    "    existing_pos = {}\n",
    "    for pos in day_folder.get_items():\n",
    "        existing_pos[pos.name] = pos.id\n",
    "    for pos in box_video_ids[day]:\n",
    "        if pos in existing_pos:\n",
    "            pos_folder = client.folder(existing_pos[pos]).get()\n",
    "        else:\n",
    "            pos_folder = day_folder.create_subfolder(pos)\n",
    "            \n",
    "        box_feature_folder_ids[day][pos] = pos_folder.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a file from box\n",
    "# return the path the movie was downloaded to\n",
    "def download_box_movie(client, movie_id):\n",
    "    if not os.path.exists(\"tmp\"):\n",
    "        os.mkdir(\"tmp\")\n",
    "    video_path = os.path.join(\"tmp\", str(uuid.uuid4()))\n",
    "    with open(video_path, \"wb\") as f:\n",
    "        client.file(movie_id).download_to(f)\n",
    "    return video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function take a subclip object defined by moviepy and creates a numpy array of # size of the subclip over the number of frames (numofframes)\n",
    "# Returns the numpy array that should be saved\n",
    "def make_np_array_from_subclip(subclip, num_frames):\n",
    "    \n",
    "    # get dimensions of subclip\n",
    "    [n_y, n_x, n_c] = subclip.get_frame(0).shape\n",
    "\n",
    "    # Create placeholder for numpy array\n",
    "    subclip_np = np.zeros((num_frames, n_y, n_x, n_c), dtype=np.uint8)\n",
    "\n",
    "    # Iterate through slices of subclip and add to numpy array\n",
    "    for nn, frame in enumerate(subclip.iter_frames()):\n",
    "        subclip_np[nn, :,:,:] = frame\n",
    "        \n",
    "    return subclip_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a hh:mm:ss string to number of seconds\n",
    "# hh: piece is optional\n",
    "\n",
    "HHMMSS_PAT = re.compile(\"(\\d+)??:??(\\d+):(\\d+)$\")\n",
    "def hhmmss_to_seconds(s):\n",
    "    m = HHMMSS_PAT.match(s)\n",
    "    g = m.groups()\n",
    "    s = 0\n",
    "    n = len(g)\n",
    "    for i in range(n):\n",
    "        if g[n-i-1] is not None:\n",
    "            s += 60**i * int(g[n-i-1])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation file should be:\n",
    "# {\"video_id\":\n",
    "#    {\"animal_id\": [\"hh:mm:ss\", ...], \"animal_id\": [\"hh:mm:ss\", ...]}\n",
    "# }\n",
    "def load_seizure_annotations(file_path):\n",
    "    with open(file_path) as f:\n",
    "        annotations = json.load(f)\n",
    "    for vid_id, video_fields in annotations.items():\n",
    "        for field, value in video_fields.items():\n",
    "            if isinstance(value, list):\n",
    "                times_in_seconds = [hhmmss_to_seconds(x) for x in value]\n",
    "                annotations[vid_id][field] = times_in_seconds        \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_annotations = load_seizure_annotations(\"seizure_annotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"position_annotations.json\") as f:\n",
    "    position_annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_video_feature_array(clip, window=10, net_output_size=1536):\n",
    "    print(\"Building Video Feature Array\")\n",
    "    duration = int(clip.duration)\n",
    "    fps = round(clip.fps)\n",
    "    frame_features = np.zeros((duration*fps, net_output_size), dtype=np.float32)\n",
    "        \n",
    "    with tf.Graph().as_default():\n",
    "        seq_input = tf.placeholder(tf.int8, (None, None, None, 3))\n",
    "        processed_images = tf.image.convert_image_dtype(seq_input, dtype=tf.float32)\n",
    "        processed_images = tf.image.resize_bilinear(processed_images, [image_size, image_size],\n",
    "                                                    align_corners=False)\n",
    "        processed_images = tf.subtract(processed_images, 0.5)\n",
    "        processed_images = tf.multiply(processed_images, 2.0)\n",
    "\n",
    "        # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "        with slim.arg_scope(inception.inception_v4_arg_scope()):\n",
    "            logits, end_points = inception.inception_v4(processed_images, \n",
    "                                                        num_classes=1001, \n",
    "                                                        is_training=False)\n",
    "\n",
    "        init_fn = slim.assign_from_checkpoint_fn(\n",
    "            'inception_v4.ckpt',\n",
    "            slim.get_model_variables('InceptionV4'))\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            init_fn(sess)\n",
    "\n",
    "            for i in tqdm_notebook(range(math.ceil(duration/window))):\n",
    "                clip_start = i * window\n",
    "                clip_end = min(duration, clip_start + window)\n",
    "                frame_start = clip_start * fps\n",
    "                frame_end = clip_end * fps\n",
    "                vid_clip = clip.subclip(clip_start, clip_end)\n",
    "                np_feed = makeNparrayfromSubclip(vid_clip, frame_end - frame_start)\n",
    "                bottleneck, tf_images = sess.run([end_points['PreLogitsFlatten'], processed_images],\n",
    "                                                 feed_dict={seq_input: np_feed})\n",
    "                frame_features[frame_start:frame_end, :] = bottleneck\n",
    "                clip_start = clip_end\n",
    "        return frame_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_slices_to_box(client, video_feature_array, day, position, mouse_id, video_id, \n",
    "                         box_feature_folder_ids, video_fps=30, chunk_size=18000, overlap = 10):\n",
    "    print(\"Uploading Slices to Box\")\n",
    "    n_chunks = math.ceil(video_feature_array.shape[0]/chunk_size)\n",
    "    for i in tqdm_notebook(range(n_chunks)):\n",
    "        start_idx = max(0, i*chunk_size - overlap * video_fps)\n",
    "        end_idx = min((i+1)*chunk_size, video_feature_array.shape[0])\n",
    "        start_time = start_idx / video_fps\n",
    "        \n",
    "        path = \"{:s}_{:s}_{:s}_{:s}_{:d}.npz\".format(day, position, mouse_id, video_id, i)\n",
    "        np.savez(path, features=video_feature_array[start_idx:end_idx, :], \n",
    "                 start_time=start_time)\n",
    "        folder_id = box_feature_folder_ids[day][position]\n",
    "        client.folder(folder_id).upload(path)\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading New Movie: MAH00011, 2019-01-18, 6 up\n"
     ]
    }
   ],
   "source": [
    "for vid_id, vid_metadata in seizure_annotations.items():\n",
    "    d = vid_metadata[\"date\"]\n",
    "    pos = vid_metadata[\"position\"]\n",
    "    movie_id = box_video_ids[d][pos][vid_id]\n",
    "    \n",
    "    print(\"Downloading New Movie: {:s}, {:s}, {:s}\".format(vid_id, d, pos))\n",
    "    vid_file_path = download_box_movie(client, movie_id)\n",
    "    vid = moviepy.editor.VideoFileClip(vid_file_path)\n",
    "    \n",
    "    for animal_id, seizure_times in vid_metadata.items():\n",
    "        if not isinstance(seizure_times, list):\n",
    "            continue\n",
    "        print(animal_id)\n",
    "        cropped_clip = moviepy.video.fx.all.crop(vid, \n",
    "                                                 x1=position_annotations[pos][animal_id][\"x1\"], \n",
    "                                                 y1=position_annotations[pos][animal_id][\"y1\"], \n",
    "                                                 x2=position_annotations[pos][animal_id][\"x2\"],\n",
    "                                                 y2=position_annotations[pos][animal_id][\"y2\"])\n",
    "        x = build_video_feature_array(cropped_clip)\n",
    "        upload_slices_to_box(client, x, d, pos, animal_id, vid_id, box_feature_folder_ids)\n",
    "        \n",
    "    os.remove(vid_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
