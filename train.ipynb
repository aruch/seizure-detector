{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import uuid\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from box_client import get_box_client\n",
    "from annotation_processor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_box_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat_video_feature_folder = client.folder('67339798174')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\"GET https://api.box.com/2.0/folders/67339798174/items?offset=0\" 401 0\n",
      "{'Date': 'Thu, 21 Feb 2019 17:47:34 GMT', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Strict-Transport-Security': 'max-age=31536000', 'WWW-Authenticate': 'Bearer realm=\"Service\", error=\"invalid_token\", error_description=\"The access token provided is invalid.\"', 'BOX-REQUEST-ID': '0ujoqfj87u8t8cp00av98rca3a4', 'Age': '0'}\n",
      "b''\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "box_feature_file_ids = {}\n",
    "for day_folder in rat_video_feature_folder.get_items():\n",
    "    for pos_folder in day_folder.get_items():\n",
    "        for feature_file in pos_folder.get_items():\n",
    "            box_feature_file_ids[feature_file.name] = feature_file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids_to_file_names = {}\n",
    "for k, v in box_feature_file_ids.items():\n",
    "    file_ids_to_file_names[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_annotations = load_seizure_annotations(\"seizure_annotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_epoch_files(n_files, box_feature_file_ids, seizure_annotations, p=0.5):\n",
    "    n_pos = int(n_files * p)\n",
    "    n_neg = n_files - n_pos\n",
    "    \n",
    "    positive_files = []\n",
    "    negative_files = []\n",
    "    for name, box_id in box_feature_file_ids.items():\n",
    "        if len(seizure_times_from_npz_filename(name, seizure_annotations)) > 0:\n",
    "            positive_files.append(box_id)\n",
    "        else:\n",
    "            negative_files.append(box_id)\n",
    "    \n",
    "    positive_examples = list(np.random.choice(positive_files, size=n_pos))\n",
    "    negative_examples = list(np.random.choice(negative_files, size=n_neg))\n",
    "    \n",
    "    return positive_examples + negative_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_box_feature_file(file_id):\n",
    "    temp_file = str(uuid.uuid4())\n",
    "    x = None\n",
    "    try:\n",
    "        with open(temp_file, \"wb\") as f:\n",
    "            client.file(file_id).download_to(f)\n",
    "        with np.load(temp_file) as data:\n",
    "            x = {\"features\": data[\"features\"], \"start_time\": data[\"start_time\"]}\n",
    "    finally:\n",
    "        if os.path.exists(temp_file):\n",
    "            os.remove(temp_file)\n",
    "            \n",
    "    return (file_id, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_epoch_files(buffer, file_ids):\n",
    "    for file_id in file_ids:\n",
    "        buffer.append(download_box_feature_file(file_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate vector y corresponding to  binary classification of video clips\n",
    "# intervals of duration = window_length annotation in seconds\n",
    "# seizure array will receive dictionary of video name of seizure times\n",
    "\n",
    "def ground_truth_label(seizure_array, window_start, window_length):\n",
    "\n",
    "   # Check if sliding window overlaps with seizure window\n",
    "   for k in seizure_array:\n",
    "\n",
    "       # Here just hard-coded 10 sec as minimum duration of seizure\n",
    "       if (window_start + window_length > k) and (window_start < k + 10):\n",
    "            return 1\n",
    "       # Windows after the 10 sec minimum duration of seizure and less than 120 secs after seizure start\n",
    "       if (window_start >= k + 10) and (window_start < k + 120):\n",
    "            return -1\n",
    "\n",
    "   # Return 0 for non-seizure windows\n",
    "   return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_positive_negative_times(epoch_examples, window_size=5, fps=29.97):\n",
    "    epoch_file_names = list(epoch_examples.keys())\n",
    "    pos_example_indices = []\n",
    "    neg_example_indices = []\n",
    "\n",
    "    for file_idx, file_name in enumerate(epoch_file_names):\n",
    "        processed_chunk = epoch_examples[file_name]\n",
    "        # video times (sec)\n",
    "        vid_start_time = processed_chunk[\"start_time\"]\n",
    "        vid_length = int(processed_chunk[\"features\"].shape[0]/fps)\n",
    "        vid_end_time = vid_start_time + vid_length\n",
    "        seizure_times = seizure_times_from_npz_filename(file_name, seizure_annotations)\n",
    "        for i in range(vid_length - window_length):\n",
    "            label = ground_truth_label(seizure_times, vid_start_time + i, window_length)\n",
    "            if label == 0:\n",
    "                neg_example_indices.append((file_idx, i))\n",
    "            elif label == 1:\n",
    "                pos_example_indices.append((file_idx, i))\n",
    "                \n",
    "    return epoch_file_names, pos_example_indices, neg_example_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_example(epoch_examples, epoch_filenames, pair, window_size = 5, fps = 30):\n",
    "    file_index = pair[0]\n",
    "    time_index = pair[1]\n",
    "    features = epoch_examples[epoch_filenames[file_index]]['features']\n",
    "    return features[time_index:time_index+window_size*fps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatch(batch_size, pos_p, pos_example_indices, neg_example_indices, epoch_examples, epoch_filenames):\n",
    "    num_pos_examples = int(batch_size*pos_p)\n",
    "    num_neg_examples = batch_size - num_pos_examples\n",
    "    \n",
    "    pos_examples = random.choices(pos_example_indices, k=num_pos_examples)\n",
    "    neg_examples = random.choices(neg_example_indices, k=num_neg_examples)\n",
    "    \n",
    "    batch_x = np.zeros((batch_size, 150, 1536))\n",
    "    batch_y = np.zeros((batch_size, 1))\n",
    "    \n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        if i < num_pos_examples:\n",
    "            pair = pos_examples[i]\n",
    "            batch_y[i] = 1\n",
    "        else:\n",
    "            pair = neg_examples[i - num_pos_examples]\n",
    "            batch_y[i] = 0\n",
    "        batch_x[i, :, :] = indices_to_example(epoch_examples, epoch_file_names, pair)\n",
    "    \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\"GET https://api.box.com/2.0/files/407341222906/content\" 401 0\n",
      "{'Date': 'Thu, 21 Feb 2019 19:07:37 GMT', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Strict-Transport-Security': 'max-age=31536000', 'WWW-Authenticate': 'Bearer realm=\"Service\", error=\"invalid_token\", error_description=\"The access token provided is invalid.\"', 'BOX-REQUEST-ID': '0h8ocr4fbdn2ausurgtd1c98mga', 'Age': '0'}\n",
      "b''\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-5bc364e8810a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_epoch_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_epoch_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_epoch_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;31m# join before launching to not bias tqdm for initial download time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mepoch_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "n_epoch_files = 2\n",
    "n_epochs = 3\n",
    "batch_size = 16\n",
    "pos_p = 1/16\n",
    "\n",
    "next_epoch_buf = []\n",
    "next_epoch_files = choose_epoch_files(n_epoch_files, box_feature_file_ids, seizure_annotations)\n",
    "t = threading.Thread(target=download_epoch_files, args=(next_epoch_buf, next_epoch_files))\n",
    "t.start(); t.join(); # join before launching to not bias tqdm for initial download time\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    t.join()\n",
    "    epoch_examples = {}\n",
    "    for vals in next_epoch_buf:\n",
    "        epoch_examples[file_ids_to_file_names[vals[0]]] = vals[1]\n",
    "    if epoch + 1 < n_epochs:\n",
    "        next_epoch_buf = []\n",
    "        next_epoch_files = choose_epoch_files(n_epoch_files, box_feature_file_ids, seizure_annotations)\n",
    "        t = threading.Thread(target=download_epoch_files, args=(next_epoch_buf, next_epoch_files))\n",
    "        t.start()\n",
    "        \n",
    "    epoch_file_names, pos_example_indices, neg_example_indices = epoch_positive_negative_times(epoch_examples)\n",
    "    n_minibatches = (len(pos_example_indices)/pos_p)//batch_size\n",
    "    for batch_i in tqdm(range(minibatches)):\n",
    "        batch_X, batch_Y = generate_minibatch(batch_size, pos_p, \n",
    "                                              pos_example_indices, neg_example_indices, \n",
    "                                              epoch_examples, epoch_file_names)\n",
    "        \n",
    "    print(epoch)\n",
    "    print(n_minibatches)\n",
    "    print(\"Sleeping\")\n",
    "    # X = np.array [training_size, 150, 1536]\n",
    "    # Y = np.array [training_size, 1]\n",
    "    time.sleep(10)\n",
    "    print(\"Done with Epoch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
